{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffeff46-10c7-426c-95f8-a5230e61346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc5529a-fa8a-41ee-8234-19f9489cd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path().cwd().parent / \"data_pipeline\" / \"notebooks\" / \"data\"\n",
    "REVIEWS_DATA_FILE = DATA_DIR / \"reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c612ce-4a0e-4917-b969-75d271648d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRN</th>\n",
       "      <th>Course Name</th>\n",
       "      <th>Instructor</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Course Number</th>\n",
       "      <th>Question</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35056</td>\n",
       "      <td>Data Str, Algo App in CmpSys (Spring 2024)</td>\n",
       "      <td>Valcourt, Scott</td>\n",
       "      <td>CS</td>\n",
       "      <td>5008</td>\n",
       "      <td>What were the strengths of this course and/or ...</td>\n",
       "      <td>Timing and Canvas are Organized.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35056</td>\n",
       "      <td>Data Str, Algo App in CmpSys (Spring 2024)</td>\n",
       "      <td>Valcourt, Scott</td>\n",
       "      <td>CS</td>\n",
       "      <td>5008</td>\n",
       "      <td>What were the strengths of this course and/or ...</td>\n",
       "      <td>very responsive professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35056</td>\n",
       "      <td>Data Str, Algo App in CmpSys (Spring 2024)</td>\n",
       "      <td>Valcourt, Scott</td>\n",
       "      <td>CS</td>\n",
       "      <td>5008</td>\n",
       "      <td>What were the strengths of this course and/or ...</td>\n",
       "      <td>Passionate, knowledgeable, extremely accommoda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35056</td>\n",
       "      <td>Data Str, Algo App in CmpSys (Spring 2024)</td>\n",
       "      <td>Valcourt, Scott</td>\n",
       "      <td>CS</td>\n",
       "      <td>5008</td>\n",
       "      <td>What were the strengths of this course and/or ...</td>\n",
       "      <td>Scott was a pleasure to have as a professor! I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35056</td>\n",
       "      <td>Data Str, Algo App in CmpSys (Spring 2024)</td>\n",
       "      <td>Valcourt, Scott</td>\n",
       "      <td>CS</td>\n",
       "      <td>5008</td>\n",
       "      <td>What were the strengths of this course and/or ...</td>\n",
       "      <td>Assignments (homework, labs), and live lecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12657</th>\n",
       "      <td>35062</td>\n",
       "      <td>Object-Oriented Design (Spring 2024)</td>\n",
       "      <td>Domino, Molly</td>\n",
       "      <td>CS</td>\n",
       "      <td>5004</td>\n",
       "      <td>What I could have done to make this course bet...</td>\n",
       "      <td>Studied more before class so that I could foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>35062</td>\n",
       "      <td>Object-Oriented Design (Spring 2024)</td>\n",
       "      <td>Domino, Molly</td>\n",
       "      <td>CS</td>\n",
       "      <td>5004</td>\n",
       "      <td>What I could have done to make this course bet...</td>\n",
       "      <td>watch vedios and books ahead may be better.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>35062</td>\n",
       "      <td>Object-Oriented Design (Spring 2024)</td>\n",
       "      <td>Domino, Molly</td>\n",
       "      <td>CS</td>\n",
       "      <td>5004</td>\n",
       "      <td>What I could have done to make this course bet...</td>\n",
       "      <td>I can utilize the additional resources provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>35062</td>\n",
       "      <td>Object-Oriented Design (Spring 2024)</td>\n",
       "      <td>Domino, Molly</td>\n",
       "      <td>CS</td>\n",
       "      <td>5004</td>\n",
       "      <td>What I could have done to make this course bet...</td>\n",
       "      <td>Spent more time outside of course hours review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>35062</td>\n",
       "      <td>Object-Oriented Design (Spring 2024)</td>\n",
       "      <td>Domino, Molly</td>\n",
       "      <td>CS</td>\n",
       "      <td>5004</td>\n",
       "      <td>What I could have done to make this course bet...</td>\n",
       "      <td>do some reading for reference materials.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12662 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRN                                 Course Name       Instructor  \\\n",
       "0      35056  Data Str, Algo App in CmpSys (Spring 2024)  Valcourt, Scott   \n",
       "1      35056  Data Str, Algo App in CmpSys (Spring 2024)  Valcourt, Scott   \n",
       "2      35056  Data Str, Algo App in CmpSys (Spring 2024)  Valcourt, Scott   \n",
       "3      35056  Data Str, Algo App in CmpSys (Spring 2024)  Valcourt, Scott   \n",
       "4      35056  Data Str, Algo App in CmpSys (Spring 2024)  Valcourt, Scott   \n",
       "...      ...                                         ...              ...   \n",
       "12657  35062        Object-Oriented Design (Spring 2024)    Domino, Molly   \n",
       "12658  35062        Object-Oriented Design (Spring 2024)    Domino, Molly   \n",
       "12659  35062        Object-Oriented Design (Spring 2024)    Domino, Molly   \n",
       "12660  35062        Object-Oriented Design (Spring 2024)    Domino, Molly   \n",
       "12661  35062        Object-Oriented Design (Spring 2024)    Domino, Molly   \n",
       "\n",
       "      Subject  Course Number  \\\n",
       "0          CS           5008   \n",
       "1          CS           5008   \n",
       "2          CS           5008   \n",
       "3          CS           5008   \n",
       "4          CS           5008   \n",
       "...       ...            ...   \n",
       "12657      CS           5004   \n",
       "12658      CS           5004   \n",
       "12659      CS           5004   \n",
       "12660      CS           5004   \n",
       "12661      CS           5004   \n",
       "\n",
       "                                                Question  \\\n",
       "0      What were the strengths of this course and/or ...   \n",
       "1      What were the strengths of this course and/or ...   \n",
       "2      What were the strengths of this course and/or ...   \n",
       "3      What were the strengths of this course and/or ...   \n",
       "4      What were the strengths of this course and/or ...   \n",
       "...                                                  ...   \n",
       "12657  What I could have done to make this course bet...   \n",
       "12658  What I could have done to make this course bet...   \n",
       "12659  What I could have done to make this course bet...   \n",
       "12660  What I could have done to make this course bet...   \n",
       "12661  What I could have done to make this course bet...   \n",
       "\n",
       "                                                  Review  \n",
       "0                       Timing and Canvas are Organized.  \n",
       "1                              very responsive professor  \n",
       "2      Passionate, knowledgeable, extremely accommoda...  \n",
       "3      Scott was a pleasure to have as a professor! I...  \n",
       "4      Assignments (homework, labs), and live lecture...  \n",
       "...                                                  ...  \n",
       "12657  Studied more before class so that I could foll...  \n",
       "12658        watch vedios and books ahead may be better.  \n",
       "12659  I can utilize the additional resources provide...  \n",
       "12660  Spent more time outside of course hours review...  \n",
       "12661           do some reading for reference materials.  \n",
       "\n",
       "[12662 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv(REVIEWS_DATA_FILE)\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6920f02a-29ce-404e-815d-98421f048ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRN                                                          35056\n",
       "Course Name             Data Str, Algo App in CmpSys (Spring 2024)\n",
       "Instructor                                         Valcourt, Scott\n",
       "Subject                                                         CS\n",
       "Course Number                                                 5008\n",
       "Question         What were the strengths of this course and/or ...\n",
       "Review                            Timing and Canvas are Organized.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4e2f91-696d-4e43-b5f1-2da18c127ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_review_instance(row: pd.Series) -> str:\n",
    "    template = f\"\"\"Metadata:\n",
    "    CRN: {row['CRN']}, Course Name: {row['Course Name']}, Instructor: {row['Instructor']},\n",
    "    Course Number: {row['Subject']}{row['Course Number']}\n",
    "\n",
    "    Question:\n",
    "    {row['Question']}\n",
    "\n",
    "    Review:\n",
    "    {row['Review']}\n",
    "    \"\"\"\n",
    "\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53b98b2-a546-4bae-b151-fd5500974496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Metadata:\\n    CRN: 35056, Course Name: Data S...\n",
       "1        Metadata:\\n    CRN: 35056, Course Name: Data S...\n",
       "2        Metadata:\\n    CRN: 35056, Course Name: Data S...\n",
       "3        Metadata:\\n    CRN: 35056, Course Name: Data S...\n",
       "4        Metadata:\\n    CRN: 35056, Course Name: Data S...\n",
       "                               ...                        \n",
       "12657    Metadata:\\n    CRN: 35062, Course Name: Object...\n",
       "12658    Metadata:\\n    CRN: 35062, Course Name: Object...\n",
       "12659    Metadata:\\n    CRN: 35062, Course Name: Object...\n",
       "12660    Metadata:\\n    CRN: 35062, Course Name: Object...\n",
       "12661    Metadata:\\n    CRN: 35062, Course Name: Object...\n",
       "Length: 12662, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringified_reviews = reviews_df.apply(stringify_review_instance, axis=1)\n",
    "stringified_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f46c47-e293-4d17-b4ab-59c22d6a8549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metadata:\\n    CRN: 35056, Course Name: Data Str, Algo App in CmpSys (Spring 2024), Instructor: Valcourt, Scott,\\n    Course Number: CS5008\\n\\n    Question:\\n    What were the strengths of this course and/or this instructor?\\n\\n    Review:\\n    Timing and Canvas are Organized.\\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringified_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0217a1-7242-46e6-bab3-1b0b2437a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c4b53fe-7d26-4d2e-ad0b-856b8c76f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Corpus\n",
    "# Convert Series to list\n",
    "stringified_reviews_list = stringified_reviews.tolist()\n",
    "\n",
    "start_time = time()\n",
    "# Step 2: Embed Texts\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedding_model.encode(stringified_reviews_list)\n",
    "end_time = time()\n",
    "print(f\"Took {end_time - start_time} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2478bb3-7287-470e-8cef-b70d67a2a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "\n",
    "# Create a collection\n",
    "collection = client.get_or_create_collection(\"naive_rag_embeddings\")\n",
    "\n",
    "# Add texts and embeddings to ChromaDB\n",
    "# for idx, (review, embedding) in tqdm(enumerate(zip(stringified_reviews_list, embeddings))):\n",
    "#     collection.add(\n",
    "#         documents=[review],\n",
    "#         metadatas=[{\"index\": idx}],\n",
    "#         ids=[str(idx)],\n",
    "#         embeddings=[embedding.tolist()]\n",
    "#     # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c79e85c-8260-44eb-9b2b-34f1e5f18a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: s-kishore.\n",
      "View Weave data at https://wandb.ai/s-kishore/naive_rag_reviews/weave\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211b70fcf0324f93bdfe85b624dd294b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving\n",
      "Generating Response\n",
      "🍩 https://wandb.ai/s-kishore/naive_rag_reviews/r/call/01940f5c-f109-7112-a8f6-0b182f81e2bc\n",
      "Based on the context provided, there isn't any specific review mentioning Prof. Raj Venkat teaching Algorithms. Therefore, I don't have enough information to provide insights into how difficult the course might be under his instruction.\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "weave.init(project_name=\"Naive_RAG_Reviews\")\n",
    "\n",
    "# Step 2: Load Qwen-2.5-1.5B-Instruct Model\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Step 3: RAG Pipeline\n",
    "class RAGPipeline:\n",
    "    SYSTEM_INSTRUCTION = \"\"\"\n",
    "    You are Course Compass, a chatbot dedicated to assisting Northeastern University graduate students with course registration each semester.\n",
    "    You have access to the latest information on available graduate courses, faculty profiles, and summarized student feedback from previous semesters.\n",
    " \n",
    "    Your goals are:\n",
    "    1. To provide accurate, up-to-date information without speculating. If you lack information about a course or question, clearly communicate that to the student.\n",
    "    2. To maintain a positive, professional tone. If past student feedback includes criticism, you should still respond diplomatically, focusing on constructive or neutral aspects.\n",
    "    3. To be concise and relevant in your responses, helping students make informed decisions about their course choices.\n",
    "\n",
    "    Important Guidelines to be followed:\n",
    "    1. The context is provided to you after retrieving reviews similar to the query being asked using a RAG pipeline.\n",
    "    Sometimes, the context is not relevant to the particular query being asked. You should always check if the context is related to the query, else reply that you don't have enough information to reply.\n",
    "    For example, the query could be about a particular course or professor, while the context would be of some other courses or professors, you should reply that you don't have enough information to these cases.\n",
    "    2. Avoid negative or speculative responses, and prioritize factual information over assumption.\n",
    "     \n",
    "    Answer the questions comprehensively using the reviews from the context by summarizing them to help the student.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model, collection, model, tokenizer):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.collection = collection\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    @weave.op\n",
    "    def retrieve(self, query, top_k=5):\n",
    "        # Embed the query\n",
    "        query_embedding = self.embedding_model.encode([query])[0]\n",
    "        \n",
    "        # Search in ChromaDB\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        return results[\"documents\"]\n",
    "\n",
    "    @weave.op\n",
    "    def generate_response(self, query, retrieved_docs):\n",
    "        # Flatten the list of retrieved documents\n",
    "        flattened_docs = [doc for sublist in retrieved_docs for doc in sublist]\n",
    "        context = \"\\n\".join(flattened_docs)\n",
    "        \n",
    "        # Prepare messages\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM_INSTRUCTION},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuery: {query}\\n\\nAnswer:\"}\n",
    "        ]\n",
    "        \n",
    "        # Tokenize and generate\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=4098,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        # Remove input tokens from output to isolate generated text\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        \n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        return response\n",
    "\n",
    "    @weave.op\n",
    "    def __call__(self, query, top_k=5):\n",
    "        print(\"Retrieving\")\n",
    "        # Step 1: Retrieve relevant documents\n",
    "        retrieved_docs = self.retrieve(query, top_k)\n",
    "\n",
    "        print(\"Generating Response\")\n",
    "        # Step 2: Generate a response\n",
    "        return self.generate_response(query, retrieved_docs)\n",
    "\n",
    "# Step 4: Use the RAG Pipeline\n",
    "rag_pipeline = RAGPipeline(embedding_model, collection, model, tokenizer)\n",
    "\n",
    "with weave.attributes({'user_id': 's-kishore', 'env': 'testing'}):\n",
    "    # Example Query\n",
    "    query = \"How difficult is Algorithms under Prof. Raj Venkat?\"\n",
    "    response = rag_pipeline(query, top_k=5)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f0b20db-c3d0-40c2-990b-a650bc49cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: s-kishore.\n",
      "View Weave data at https://wandb.ai/s-kishore/naive_rag_reviews/weave\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c00a4bd5dd44bd8f6025634828e39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving\n",
      "Reranking\n",
      "Generating Response\n",
      "🍩 https://wandb.ai/s-kishore/naive_rag_reviews/r/call/01940f5e-1f1b-7480-91b9-7b5ed86bb8b7\n",
      "Based on the reviews, the strengths of the Foundations of Artificial Intelligence course taught by Prof. Raj Venkat include:\n",
      "\n",
      "- **Engagement and Expertise**: Prof. Venkat is described as intelligent and engaging, and he navigates the balance between providing adequate and detailed information well.\n",
      "- **Caring and Supportive**: He is noted for his willingness to spend extra time explaining concepts and helping students understand the material.\n",
      "- **Course Content**: While specific details about assignments and projects are mentioned, the general sentiment is positive regarding the content covered in the course.\n",
      "\n",
      "Overall, students appreciate Prof. Venkat's approach to teaching and his dedication to student understanding.\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "weave.init(project_name=\"Naive_RAG_Reviews\")\n",
    "\n",
    "# Step 2: Load Qwen-2.5-1.5B-Instruct Model\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Reranker Class\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "class Reranker:\n",
    "    def __init__(self, reranker_model_name=\"cross-encoder/ms-marco-MiniLM-L-12-v2\", device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the Reranker with a cross-encoder model.\n",
    "        Args:\n",
    "            reranker_model_name: Name of the Hugging Face model for reranking.\n",
    "            device: Device to run the model on (\"cpu\" or \"cuda\").\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(reranker_model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(reranker_model_name).to(device)\n",
    "\n",
    "    def rerank(self, query, documents, top_k=None):\n",
    "        \"\"\"\n",
    "        Rerank the documents based on their relevance to the query.\n",
    "        Args:\n",
    "            query: The input query string.\n",
    "            documents: List of documents to rerank.\n",
    "            top_k: Number of top documents to return (default: all).\n",
    "        Returns:\n",
    "            List of reranked documents.\n",
    "        \"\"\"\n",
    "        # Prepare query-document pairs\n",
    "        pairs = [[query, doc] for doc in documents]\n",
    "        \n",
    "        # Tokenize inputs for the cross-encoder\n",
    "        inputs = self.tokenizer(pairs, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        inputs = {key: value.to(self.device) for key, value in inputs.items()}\n",
    "        \n",
    "        # Predict relevance scores\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            scores = outputs.logits.squeeze(-1)  # Extract scores from logits\n",
    "        \n",
    "        # Sort documents by scores in descending order\n",
    "        ranked_indices = scores.argsort(descending=True)\n",
    "        ranked_documents = [documents[idx] for idx in ranked_indices]\n",
    "        \n",
    "        # Return the top_k documents if specified\n",
    "        return ranked_documents[:top_k] if top_k else ranked_documents\n",
    "\n",
    "\n",
    "# Step 3: RAG Pipeline with Reranking\n",
    "class RAGPipeline:\n",
    "    SYSTEM_INSTRUCTION = \"\"\"\n",
    "    You are Course Compass, a chatbot dedicated to assisting Northeastern University graduate students with course registration each semester.\n",
    "    You have access to the latest information on available graduate courses, faculty profiles, and summarized student feedback from previous semesters.\n",
    " \n",
    "    Your goals are:\n",
    "    1. To provide accurate, up-to-date information without speculating. If you lack information about a course or question, clearly communicate that to the student.\n",
    "    2. To maintain a positive, professional tone. If past student feedback includes criticism, you should still respond diplomatically, focusing on constructive or neutral aspects.\n",
    "    3. To be concise and relevant in your responses, helping students make informed decisions about their course choices.\n",
    "\n",
    "    Important Guidelines to be followed:\n",
    "    1. The context is provided to you after retrieving reviews similar to the query being asked using a RAG pipeline.\n",
    "    Sometimes, the context is not relevant to the particular query being asked. You should always check if the context is related to the query, else reply that you don't have enough information to reply.\n",
    "    For example, the query could be about a particular course or professor, while the context would be of some other courses or professors, you should reply that you don't have enough information to these cases.\n",
    "    2. Avoid negative or speculative responses, and prioritize factual information over assumption.\n",
    "     \n",
    "    Answer the questions comprehensively using the reviews from the context by summarizing them to help the student.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model, collection, model, tokenizer, reranker):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.collection = collection\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.reranker = reranker\n",
    "\n",
    "    @weave.op\n",
    "    def retrieve(self, query, top_k=5):\n",
    "        # Embed the query\n",
    "        query_embedding = self.embedding_model.encode([query])[0]\n",
    "        \n",
    "        # Search in ChromaDB\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        return results[\"documents\"]\n",
    "\n",
    "    @weave.op\n",
    "    def rerank_documents(self, query, retrieved_docs, top_k):\n",
    "        # Flatten the list of retrieved documents\n",
    "        flattened_docs = [doc for sublist in retrieved_docs for doc in sublist]\n",
    "        \n",
    "        # Rerank using the reranker\n",
    "        reranked_docs = self.reranker.rerank(query, flattened_docs, top_k=top_k)\n",
    "        return reranked_docs\n",
    "\n",
    "    @weave.op\n",
    "    def generate_response(self, query, retrieved_docs):\n",
    "        # Join reranked documents into a context string\n",
    "        context = \"\\n\".join(retrieved_docs)\n",
    "        \n",
    "        # Prepare messages\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM_INSTRUCTION},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuery: {query}\\n\\nAnswer:\"}\n",
    "        ]\n",
    "        \n",
    "        # Tokenize and generate\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=4098,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        # Remove input tokens from output to isolate generated text\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        \n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        return response\n",
    "\n",
    "    @weave.op\n",
    "    def __call__(self, query, top_k=5):\n",
    "        print(\"Retrieving\")\n",
    "        # Step 1: Retrieve relevant documents\n",
    "        retrieved_docs = self.retrieve(query, top_k)\n",
    "\n",
    "        print(\"Reranking\")\n",
    "        # Step 2: Rerank the retrieved documents\n",
    "        reranked_docs = self.rerank_documents(query, retrieved_docs, top_k)\n",
    "\n",
    "        print(\"Generating Response\")\n",
    "        # Step 3: Generate a response\n",
    "        return self.generate_response(query, reranked_docs)\n",
    "\n",
    "# Step 4: Use the RAG Pipeline with Reranking\n",
    "reranker = Reranker(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rag_pipeline = RAGPipeline(embedding_model, collection, model, tokenizer, reranker)\n",
    "\n",
    "with weave.attributes({'user_id': 's-kishore', 'env': 'testing'}):\n",
    "    # Example Query\n",
    "    query = \"Can you summarize the reviews for the Foundations of Artificial Intelligence under Prof. Raj Venkat?\"\n",
    "    response = rag_pipeline(query, top_k=5)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658a6d4-7ea0-49ba-b019-c5d122fe5e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
