{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K3Hr9GuiXewK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "! pip install chromadb sentence_transformers transformers numpy pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H30zLIEzXqIF",
        "outputId": "7089142d-26d9-4600-b2ff-b8049ca1aed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TJcbqclHXewL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/course_registration/courses.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpKT4ONUXewL",
        "outputId": "a945a98f-e62d-4ed3-abc5-d8768cc97a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     CRN Campus Description                           Course Title  \\\n",
            "0  34154             Online  Computer Science and Its Applications   \n",
            "1  32828             Boston                        Lab for CS 1100   \n",
            "2  32829             Boston                        Lab for CS 1100   \n",
            "3  32830             Boston                        Lab for CS 1100   \n",
            "4  34155             Online                     First Year Seminar   \n",
            "\n",
            "  Subject Course       Faculty Name  \\\n",
            "0         CS1100   Lieberherr, Karl   \n",
            "1         CS1101   Lieberherr, Karl   \n",
            "2         CS1101   Lieberherr, Karl   \n",
            "3         CS1101   Lieberherr, Karl   \n",
            "4         CS1200  Wassinger, Claire   \n",
            "\n",
            "                                  Course Description         Term  Begin Time  \\\n",
            "0  Introduces students to the field of computer s...  Spring 2025         NaN   \n",
            "1  Accompanies CS 1100. Involves experiments and ...  Spring 2025       800.0   \n",
            "2  Accompanies CS 1100. Involves experiments and ...  Spring 2025       915.0   \n",
            "3  Accompanies CS 1100. Involves experiments and ...  Spring 2025      1030.0   \n",
            "4  Seeks to support students in their transition ...  Spring 2025         NaN   \n",
            "\n",
            "   End Time    Days Prerequisites  \n",
            "0       NaN     NaN            []  \n",
            "1     905.0  Friday            []  \n",
            "2    1020.0  Friday            []  \n",
            "3    1135.0  Friday            []  \n",
            "4       NaN     NaN            []  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9ubM5FeXewM",
        "outputId": "98899686-9b2a-425e-f5ff-d6643f3e5691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 11)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-qRK_BucXewM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def clean_time(time_val):\n",
        "    if pd.isna(time_val) or time_val == '' or time_val == 0:\n",
        "        return None\n",
        "    return str(int(time_val)).zfill(4)\n",
        "\n",
        "\n",
        "def format_time(time_str):\n",
        "    if not time_str or len(time_str) != 4:\n",
        "        return None\n",
        "    hours = int(time_str[:2])\n",
        "    minutes = time_str[2:]\n",
        "    period = \"AM\" if hours < 12 else \"PM\"\n",
        "    if hours > 12:\n",
        "        hours -= 12\n",
        "    elif hours == 0:\n",
        "        hours = 12\n",
        "    return f\"{hours}:{minutes} {period}\"\n",
        "\n",
        "\n",
        "\n",
        "def course_to_sentence(row):\n",
        "    crn = str(row.get('CRN', ''))\n",
        "    campus = row.get('Campus Description', '')\n",
        "    title = row.get('Course Title', '')\n",
        "    subject_course = row.get('Subject Course', '')\n",
        "    faculty = row.get('Faculty Name', '')\n",
        "    description = row.get('Course Description', '')\n",
        "    term = row.get('Term', '')\n",
        "\n",
        "    begin_time = clean_time(row.get('Begin Time', ''))\n",
        "    end_time = clean_time(row.get('End Time', ''))\n",
        "    days = row.get('Days', '')\n",
        "    prerequisites = row.get('Prerequisites', '[]')\n",
        "\n",
        "\n",
        "    sentence_parts = [f\"{subject_course} (CRN: {crn}), {title},\"]\n",
        "\n",
        "\n",
        "    if campus.lower() == 'online':\n",
        "        sentence_parts.append(\"is an online course\")\n",
        "    elif campus.lower() == 'no campus, no room needed':\n",
        "        sentence_parts.append(\"is a self-paced course\")\n",
        "    else:\n",
        "        sentence_parts.append(f\"is offered at {campus}\")\n",
        "\n",
        "\n",
        "    sentence_parts.append(f\"for {term}\")\n",
        "\n",
        "\n",
        "    if begin_time and end_time and days:\n",
        "        formatted_begin = format_time(begin_time)\n",
        "        formatted_end = format_time(end_time)\n",
        "        schedule = f\"with classes scheduled {days} from {formatted_begin} to {formatted_end}\"\n",
        "        sentence_parts.append(schedule)\n",
        "\n",
        "\n",
        "    if faculty:\n",
        "        sentence_parts.append(f\"taught by Professor {faculty}\")\n",
        "\n",
        "\n",
        "    sentence = \" \".join(sentence_parts) + \".\"\n",
        "\n",
        "\n",
        "    if description:\n",
        "        description = ' '.join(str(description).split())\n",
        "        sentence += f\" {description}\"\n",
        "\n",
        "\n",
        "    if prerequisites == '[]' or not prerequisites or prerequisites.strip() == '':\n",
        "        sentence += \" This course is open to all students with no prerequisites required.\"\n",
        "    else:\n",
        "        prereqs = prerequisites.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
        "        if prereqs:\n",
        "            sentence += f\" Prerequisites for this course: {prereqs}.\"\n",
        "\n",
        "\n",
        "    return ' '.join(sentence.split())\n",
        "\n",
        "\n",
        "def course_to_structured_text(row):\n",
        "    \"\"\"Convert course data to structured, searchable format\"\"\"\n",
        "    # Course identification\n",
        "    metadata_section = (\n",
        "        \"=== COURSE METADATA ===\\n\"\n",
        "        f\"Course Code: {row.get('Subject Course', '')}\\n\"\n",
        "        f\"CRN: {str(row.get('CRN', ''))}\\n\"\n",
        "        f\"Title: {row.get('Course Title', '')}\\n\"\n",
        "    )\n",
        "\n",
        "    # Location information\n",
        "    campus = row.get('Campus Description', '')\n",
        "    format_type = (\"Online\" if campus.lower() == 'online'\n",
        "                  else \"Self-paced\" if campus.lower() == 'no campus, no room needed'\n",
        "                  else \"In-Person\")\n",
        "    location_section = (\n",
        "        \"=== LOCATION ===\\n\"\n",
        "        f\"Campus: {campus}\\n\"\n",
        "        f\"Format: {format_type}\\n\"\n",
        "    )\n",
        "\n",
        "    # Schedule information\n",
        "    begin_time = clean_time(row.get('Begin Time', ''))\n",
        "    end_time = clean_time(row.get('End Time', ''))\n",
        "    days = row.get('Days', '')\n",
        "    schedule_section = \"=== SCHEDULE ===\\n\"\n",
        "    if begin_time and end_time and days:\n",
        "        schedule_section += (f\"Days: {days}\\n\"\n",
        "                           f\"Time: {format_time(begin_time)} to {format_time(end_time)}\\n\")\n",
        "    else:\n",
        "        schedule_section += \"Schedule: Flexible/Self-paced\\n\"\n",
        "\n",
        "    # Instructor information\n",
        "    faculty = row.get('Faculty Name', '')\n",
        "    instructor_section = (\n",
        "        \"=== INSTRUCTOR ===\\n\"\n",
        "        f\"Professor: {faculty if faculty else 'Not specified'}\\n\"\n",
        "    )\n",
        "\n",
        "    # Course details including prerequisites\n",
        "    prerequisites = row.get('Prerequisites', '[]')\n",
        "    prereq_text = (\"None required\" if prerequisites == '[]' or not prerequisites or prerequisites.strip() == ''\n",
        "                  else prerequisites.strip('[]').replace(\"'\", \"\").replace('\"', ''))\n",
        "    details_section = (\n",
        "        \"=== COURSE DETAILS ===\\n\"\n",
        "        f\"Term: {row.get('Term', '')}\\n\"\n",
        "        f\"Prerequisites: {prereq_text}\\n\"\n",
        "    )\n",
        "\n",
        "    # Course description\n",
        "    description = row.get('Course Description', '')\n",
        "    description_section = (\n",
        "        \"=== DESCRIPTION ===\\n\"\n",
        "        f\"{description if description else 'No description available'}\\n\"\n",
        "    )\n",
        "\n",
        "    # Combine all sections\n",
        "    return (f\"{metadata_section.lower()}\\n\"\n",
        "            f\"{location_section.lower()}\\n\"\n",
        "            f\"{schedule_section.lower()}\\n\"\n",
        "            f\"{instructor_section.lower()}\\n\"\n",
        "            f\"{details_section.lower()}\\n\"\n",
        "            f\"{description_section.lower()}\")\n",
        "\n",
        "def process_course_data(file_path):\n",
        "    \"\"\"Process entire course dataset and convert to sentences.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    # return [course_to_sentence(row) for _, row in df.iterrows()]\n",
        "    return [course_to_structured_text(row) for _, row in df.iterrows()]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8W7gSBxXewM"
      },
      "outputs": [],
      "source": [
        "course_sentences = process_course_data('/content/drive/MyDrive/course_registration/courses.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcXsEwHRXewM",
        "outputId": "711f5897-3e53-423e-e680-e333ce8f7a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== course metadata ===\n",
            "course code: cs5540\n",
            "crn: 40567\n",
            "title: game programming\n",
            "\n",
            "=== location ===\n",
            "campus: portland, maine\n",
            "format: in-person\n",
            "\n",
            "=== schedule ===\n",
            "days: monday\n",
            "time: 1:00 pm to 4:20 pm\n",
            "\n",
            "=== instructor ===\n",
            "professor: talaei khoei, tala\n",
            "\n",
            "=== course details ===\n",
            "term: spring 2025\n",
            "prerequisites: none required\n",
            "\n",
            "=== description ===\n",
            "covers the skills needed to develop easily scalable and modifiable scripts that can be used to implement various game mechanics common to most game genres. programming is an integral part of the digital game design and development life cycle. designed as a foundational game programming course covering numerous aspects of game programming.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(course_sentences[300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93pxyIcpXewN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "# Utility functions remain the same\n",
        "def clean_time(time_val):\n",
        "    if pd.isna(time_val) or time_val == '' or time_val == 0:\n",
        "        return None\n",
        "    return str(int(time_val)).zfill(4)\n",
        "\n",
        "def format_time(time_str):\n",
        "    if not time_str or len(time_str) != 4:\n",
        "        return None\n",
        "    hours = int(time_str[:2])\n",
        "    minutes = time_str[2:]\n",
        "    period = \"AM\" if hours < 12 else \"PM\"\n",
        "    if hours > 12:\n",
        "        hours -= 12\n",
        "    elif hours == 0:\n",
        "        hours = 12\n",
        "    return f\"{hours}:{minutes} {period}\"\n",
        "\n",
        "def course_to_structured_text(row):\n",
        "    metadata_section = (\n",
        "        \"=== COURSE METADATA ===\\n\"\n",
        "        f\"Course Code: {row.get('Subject Course', '')}\\n\"\n",
        "        f\"CRN: {str(row.get('CRN', ''))}\\n\"\n",
        "        f\"Title: {row.get('Course Title', '')}\\n\"\n",
        "    )\n",
        "\n",
        "    campus = row.get('Campus Description', '')\n",
        "    format_type = (\"Online\" if campus.lower() == 'online'\n",
        "                  else \"Self-paced\" if campus.lower() == 'no campus, no room needed'\n",
        "                  else \"In-Person\")\n",
        "    location_section = (\n",
        "        \"=== LOCATION ===\\n\"\n",
        "        f\"Campus: {campus}\\n\"\n",
        "        f\"Format: {format_type}\\n\"\n",
        "    )\n",
        "\n",
        "    begin_time = clean_time(row.get('Begin Time', ''))\n",
        "    end_time = clean_time(row.get('End Time', ''))\n",
        "    days = row.get('Days', '')\n",
        "    schedule_section = \"=== SCHEDULE ===\\n\"\n",
        "    if begin_time and end_time and days:\n",
        "        schedule_section += (f\"Days: {days}\\n\"\n",
        "                           f\"Time: {format_time(begin_time)} to {format_time(end_time)}\\n\")\n",
        "    else:\n",
        "        schedule_section += \"Schedule: Flexible/Self-paced\\n\"\n",
        "\n",
        "    faculty = row.get('Faculty Name', '')\n",
        "    instructor_section = (\n",
        "        \"=== INSTRUCTOR ===\\n\"\n",
        "        f\"Professor: {faculty if faculty else 'Not specified'}\\n\"\n",
        "    )\n",
        "\n",
        "    prerequisites = row.get('Prerequisites', '[]')\n",
        "    prereq_text = (\"None required\" if prerequisites == '[]' or not prerequisites or prerequisites.strip() == ''\n",
        "                  else prerequisites.strip('[]').replace(\"'\", \"\").replace('\"', ''))\n",
        "    details_section = (\n",
        "        \"=== COURSE DETAILS ===\\n\"\n",
        "        f\"Term: {row.get('Term', '')}\\n\"\n",
        "        f\"Prerequisites: {prereq_text}\\n\"\n",
        "    )\n",
        "\n",
        "    description = row.get('Course Description', '')\n",
        "    description_section = (\n",
        "        \"=== DESCRIPTION ===\\n\"\n",
        "        f\"{description if description else 'No description available'}\\n\"\n",
        "    )\n",
        "\n",
        "    return (f\"{metadata_section.lower()}\\n\"\n",
        "            f\"{location_section.lower()}\\n\"\n",
        "            f\"{schedule_section.lower()}\\n\"\n",
        "            f\"{instructor_section.lower()}\\n\"\n",
        "            f\"{details_section.lower()}\\n\"\n",
        "            f\"{description_section.lower()}\")\n",
        "\n",
        "def process_course_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return [course_to_structured_text(row) for _, row in df.iterrows()]\n",
        "\n",
        "class CourseSearchSystem:\n",
        "    def __init__(self):\n",
        "        self.documents = None\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            lowercase=True,\n",
        "            token_pattern=r'(?u)\\b\\w+\\b|===\\s*\\w+\\s*===',  # Include section markers\n",
        "            ngram_range=(1, 2)  # Include bigrams for better matching\n",
        "        )\n",
        "        self.tfidf_matrix = None\n",
        "\n",
        "    def preprocess_query(self, query):\n",
        "        \"\"\"Extract structured information from query\"\"\"\n",
        "        query_parts = {\n",
        "            'course': None,\n",
        "            'professor': None,\n",
        "            'term': None,\n",
        "            'campus': None\n",
        "        }\n",
        "\n",
        "        query = query.lower()\n",
        "\n",
        "        # Extract course information\n",
        "        if 'algorithms' in query:\n",
        "            query_parts['course'] = 'algorithms'\n",
        "        elif 'artificial intelligence' in query:\n",
        "            query_parts['course'] = 'artificial intelligence'\n",
        "\n",
        "        # Extract professor name\n",
        "        if 'rajagopal' in query or 'venkatesaramani' in query:\n",
        "            query_parts['professor'] = 'venkatesaramani, rajagopal'\n",
        "\n",
        "        # Extract term\n",
        "        if 'spring 2025' in query:\n",
        "            query_parts['term'] = 'spring 2025'\n",
        "\n",
        "        # Extract campus\n",
        "        if 'boston' in query:\n",
        "            query_parts['campus'] = 'boston'\n",
        "\n",
        "        return query_parts\n",
        "\n",
        "    def enhance_query(self, query):\n",
        "        \"\"\"Enhance query with structural information\"\"\"\n",
        "        query_parts = self.preprocess_query(query)\n",
        "        enhanced_query = query.lower()\n",
        "\n",
        "        if query_parts['course']:\n",
        "            enhanced_query += f\" === course metadata === title: {query_parts['course']}\"\n",
        "        if query_parts['professor']:\n",
        "            enhanced_query += f\" === instructor === professor: {query_parts['professor']}\"\n",
        "        if query_parts['term']:\n",
        "            enhanced_query += f\" === course details === term: {query_parts['term']}\"\n",
        "        if query_parts['campus']:\n",
        "            enhanced_query += f\" === location === campus: {query_parts['campus']}\"\n",
        "\n",
        "        return enhanced_query, query_parts\n",
        "\n",
        "    def add_course_sentences_to_db(self, course_data):\n",
        "        self.documents = [doc for doc in course_data if doc is not None]\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(self.documents)\n",
        "\n",
        "    def query_courses(self, query_text, n_results=5):\n",
        "        enhanced_query, query_parts = self.enhance_query(query_text)\n",
        "\n",
        "        try:\n",
        "            if self.tfidf_matrix is None:\n",
        "                return {\"documents\": [[\"No documents indexed\"]]}\n",
        "\n",
        "            query_vec = self.vectorizer.transform([enhanced_query])\n",
        "            scores = (query_vec @ self.tfidf_matrix.T).toarray()[0]\n",
        "            top_n = np.argsort(scores)[-n_results:][::-1]\n",
        "\n",
        "            filtered_results = []\n",
        "            for idx in top_n:\n",
        "                doc = self.documents[idx]\n",
        "                doc_lower = doc.lower()\n",
        "\n",
        "                matches_all = True\n",
        "                if query_parts['course'] and query_parts['course'] not in doc_lower:\n",
        "                    matches_all = False\n",
        "                if query_parts['professor'] and query_parts['professor'] not in doc_lower:\n",
        "                    matches_all = False\n",
        "                if query_parts['term'] and query_parts['term'] not in doc_lower:\n",
        "                    matches_all = False\n",
        "\n",
        "                if matches_all:\n",
        "                    filtered_results.append(doc)\n",
        "\n",
        "            return {\"documents\": [filtered_results[:n_results]]}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during search: {e}\")\n",
        "            return {\"documents\": [[\"Error occurred during search\"]]}\n",
        "\n",
        "class RAGPipeline:\n",
        "    SYSTEM_INSTRUCTION = \"\"\"\n",
        "    You are Curriculum compass, a chatbot which helps Northeastern University students find course offerings of their choice for the Spring 2025 semester.\n",
        "\n",
        "    You have access to all the course offerings for the Spring 2025 semester, your objective is to use this context to answer student questions.\n",
        "\n",
        "    Instructions:\n",
        "    1. Students may not mention the names of the courses properly. Their input could have typo's, mistakes. For example, students could input 'PDP' instead of\n",
        "    'Programming Design Paradigm' or they could mention 'Raj Venkat' instead of the full name of the professor 'Rajagopal Venkatesaramani'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, course_search_system):\n",
        "        self.course_search_system = course_search_system\n",
        "        model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=\"auto\",\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def generate_response(self, query, retrieved_docs):\n",
        "        context = \"\\n\\n\".join([doc for sublist in retrieved_docs for doc in sublist])\n",
        "        prompt = f\"\"\"Context:{context}, Query: {query}\"\"\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": self.SYSTEM_INSTRUCTION},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "        generated_ids = self.model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=4500,\n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):]\n",
        "            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "\n",
        "        return self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    def __call__(self, query, top_k=10):\n",
        "        print(f\"Processing query: {query}\")\n",
        "        print(\"Retrieving relevant course information...\")\n",
        "        results = self.course_search_system.query_courses(query, top_k)\n",
        "\n",
        "        print(\"Generating response...\")\n",
        "        response = self.generate_response(query, results[\"documents\"])\n",
        "        return response\n",
        "\n",
        "def main():\n",
        "    # Load course data\n",
        "    course_sentences = process_course_data('/content/drive/MyDrive/course_registration/courses.csv')\n",
        "\n",
        "    # Initialize TFIDF system\n",
        "    search_system = CourseSearchSystem()\n",
        "    search_system.add_course_sentences_to_db(course_sentences)\n",
        "\n",
        "    # Create RAG pipeline\n",
        "    rag_pipeline = RAGPipeline(search_system)\n",
        "\n",
        "    # Test queries\n",
        "    example_queries = [\n",
        "        \"Are there any prerequisite courses for Artificial Intelligence for Human Computer Interaction?\"\n",
        "    ]\n",
        "\n",
        "    # Process queries\n",
        "    for query in example_queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"Query: {query}\")\n",
        "        try:\n",
        "            response = rag_pipeline(query)\n",
        "            print(\"Response:\")\n",
        "            print(response)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XwrrzFEK5ye"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NNrLEy5K51C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GebrkhgBK53n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD4lz6-EK56H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEpEZaB9K58t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReidjyW_K5-8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iMzPFdMK6BM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH5uRnmaK6Ln"
      },
      "source": [
        "Experimentation to find the best RAG-retreiver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ijwpgS2_XewN"
      },
      "outputs": [],
      "source": [
        "# import chromadb\n",
        "# import torch\n",
        "# import pandas as pd\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# import numpy as np\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# import re\n",
        "\n",
        "# class CustomEmbeddingFunction:\n",
        "#     def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
        "#         self.model = SentenceTransformer(model_name)\n",
        "\n",
        "#     def __call__(self, input):\n",
        "#         if isinstance(input, str):\n",
        "#             input = [input]\n",
        "#         embeddings = self.model.encode(input, convert_to_numpy=True)\n",
        "#         if len(embeddings.shape) == 1:\n",
        "#             embeddings = np.expand_dims(embeddings, axis=0)\n",
        "#         return embeddings.tolist()\n",
        "\n",
        "# class CourseSearchSystem:\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         embedding_model_name: str = \"all-MiniLM-L6-v2\",\n",
        "#         device: str = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "#     ):\n",
        "#         self.device = device\n",
        "#         self.embedding_function = CustomEmbeddingFunction(embedding_model_name)\n",
        "#         self.chroma_client = chromadb.Client()\n",
        "\n",
        "#         try:\n",
        "#             self.chroma_client.delete_collection(name=\"course_embeddings\")\n",
        "#         except:\n",
        "#             pass\n",
        "\n",
        "#         self.collection = self.chroma_client.create_collection(\n",
        "#             name=\"course_embeddings\",\n",
        "#             embedding_function=self.embedding_function\n",
        "#         )\n",
        "\n",
        "\n",
        "#     def add_course_sentences_to_db(self, course_data):\n",
        "#         \"\"\"Process and add structured course descriptions to the database\"\"\"\n",
        "\n",
        "#         documents = [doc for doc in course_data if doc is not None]\n",
        "#         ids = [f\"course_{i}\" for i in range(len(documents))]\n",
        "\n",
        "#         # print(f\"Sample metadata: {metadatas[0]}\\n\\n Sample document: {documents[0]}\\n\\n Sample ID: {ids[0]}\")\n",
        "\n",
        "#         self.collection.add(\n",
        "#             documents=documents,\n",
        "#             ids=ids\n",
        "#         )\n",
        "\n",
        "#     def query_courses(self, query_text, n_results=5):\n",
        "#         \"\"\"Enhanced query function for structured text\"\"\"\n",
        "#         # Clean and normalize query\n",
        "#         query_text = query_text.lower()\n",
        "\n",
        "#         return self.collection.query(\n",
        "#             query_texts=[query_text],\n",
        "#             n_results=n_results,\n",
        "#             include=[\"documents\"]\n",
        "#         )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "HbQvs5OpXewN"
      },
      "outputs": [],
      "source": [
        "# course_search_system = CourseSearchSystem()\n",
        "# course_search_system.add_course_sentences_to_db(course_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "srk3IUBaXewO"
      },
      "outputs": [],
      "source": [
        "# course_search_system.query_courses(\"who teaches algorithms offered for the spring?\", n_results=5)[\"documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "msasJRWkXewO"
      },
      "outputs": [],
      "source": [
        "# #Implementing the RAG pipeline\n",
        "# class RAGPipeline:\n",
        "#     SYSTEM_INSTRUCTION = \"\"\"\n",
        "#     You are 'Course Compass', an AI assistant for a university's course registration system. Your primary role is to provide precise and accurate course information based STRICTLY on the provided context, with specific focus on matching query details to context entries accurately.\n",
        "\n",
        "#     Key guidelines:\n",
        "#     1. Closely match each detail in the user's query to the contextâ€”course codes, professor names, course timings, and locations must be checked for exact matches or very close approximations.\n",
        "#     2. Extract and provide comprehensive details about:\n",
        "#       - Course format (online/in-person)\n",
        "#       - Schedule and timing\n",
        "#       - Prerequisites\n",
        "#       - Course description\n",
        "#     3. If a query references details seemingly not present in the context, double-check for synonyms or variations before stating absence.\n",
        "#     4. Clarify any mismatches or ambiguities without making assumptions about unmentioned details.\n",
        "\n",
        "#     Response protocol:\n",
        "#     1. Directly address each specific detail mentioned in the query.\n",
        "#     2. Clearly state when a detail from the query does not exactly match but is closely related, providing the related information.\n",
        "#     3. Indicate when no matching information is found but also mention similar available information.\n",
        "#     4. Structure responses to clearly separate confirmed details from those that are not available or ambiguous.\n",
        "\n",
        "#     Response format:\n",
        "#     1. Course Information: Code, title, format, campus\n",
        "#     2. Professor Details: Names, teaching schedules, and any specific notes on their courses\n",
        "#     3. Schedule Information: Detailed day and time listings\n",
        "#     4. Course Content/Description: Detailed summary from the provided context\n",
        "#     5. Prerequisites: Listed if specifically mentioned\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, course_search_system):\n",
        "#         self.course_search_system = course_search_system\n",
        "#         model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "#         self.model = AutoModelForCausalLM.from_pretrained(\n",
        "#             model_name,\n",
        "#             torch_dtype=\"auto\",\n",
        "#             device_map=\"auto\"\n",
        "#         )\n",
        "#         self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#     def generate_response(self, query, retrieved_docs):\n",
        "#         # Prepare context by joining all retrieved documents\n",
        "#         context = \"\\n\\n\".join([doc for sublist in retrieved_docs for doc in sublist])\n",
        "\n",
        "#         # Create a detailed prompt for the model\n",
        "#         prompt = f\"\"\"Based on the provided course information, please answer the following query.\n",
        "\n",
        "#         Query: {query}\n",
        "\n",
        "#         Context:\n",
        "#         {context}\n",
        "\n",
        "#         Instructions:\n",
        "#         1. Verify the presence of the course or professor mentioned in the query against the context.\n",
        "#         2. If there is a mismatch or absence of information, explicitly state that the information is not available.\n",
        "#         3. Provide details only if they are specifically mentioned and confirmed in the context.\n",
        "#         4. Ignore and clarify the absence of unrelated or unconfirmed details.\n",
        "\n",
        "#         Response:\n",
        "#         \"\"\"\n",
        "\n",
        "#         # Prepare messages for the model\n",
        "#         messages = [\n",
        "#             {\"role\": \"system\", \"content\": self.SYSTEM_INSTRUCTION},\n",
        "#             {\"role\": \"user\", \"content\": prompt}\n",
        "#         ]\n",
        "\n",
        "#         # Generate response using the model\n",
        "#         text = self.tokenizer.apply_chat_template(\n",
        "#             messages,\n",
        "#             tokenize=False,\n",
        "#             add_generation_prompt=True\n",
        "#         )\n",
        "\n",
        "#         model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "#         generated_ids = self.model.generate(\n",
        "#             **model_inputs,\n",
        "#             max_new_tokens=4500,\n",
        "#             temperature=0.1\n",
        "#         )\n",
        "\n",
        "#         # Process the generated response\n",
        "#         generated_ids = [\n",
        "#             output_ids[len(input_ids):]\n",
        "#             for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "#         ]\n",
        "\n",
        "#         return self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "#     def __call__(self, query, top_k=5):\n",
        "#         print(f\"Processing query: {query}\")\n",
        "#         print(\"Retrieving relevant course information...\")\n",
        "#         results = self.course_search_system.query_courses(query, top_k)\n",
        "\n",
        "#         print(\"Generating response...\")\n",
        "#         response = self.generate_response(query, results[\"documents\"])\n",
        "#         return response\n",
        "\n",
        "# def main():\n",
        "#     print(\"Initializing RAG pipeline...\")\n",
        "#     rag_pipeline = RAGPipeline(course_search_system)\n",
        "\n",
        "\n",
        "#     example_queries = [\n",
        "#         \"What are the courses professor shesh amit is teaching?\"\n",
        "#     ]\n",
        "\n",
        "#     # Process each query\n",
        "#     for query in example_queries:\n",
        "#         print(\"\\n\" + \"=\"*50)\n",
        "#         print(f\"Query: {query}\")\n",
        "#         response = rag_pipeline(query,5)\n",
        "#         print(\"\\nResponse:\")\n",
        "#         print(response)\n",
        "#         print(\"=\"*50)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "of4V1Nr9mXfp"
      },
      "outputs": [],
      "source": [
        "# course_search_system.query_courses(\"who offers Foundations of Artificial Intelligence offered for Spring 2025?\")[\"documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "kFC_6hmizuBy"
      },
      "outputs": [],
      "source": [
        "# course_search_system.query_courses(\"shesh amit\", n_results=5)[\"documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "H-9o1BMjzzk2"
      },
      "outputs": [],
      "source": [
        "# import chromadb\n",
        "# import torch\n",
        "# import pandas as pd\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# import numpy as np\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# from rank_bm25 import BM25Okapi\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# import re\n",
        "\n",
        "# # Utility functions\n",
        "# def clean_time(time_val):\n",
        "#     if pd.isna(time_val) or time_val == '' or time_val == 0:\n",
        "#         return None\n",
        "#     return str(int(time_val)).zfill(4)\n",
        "\n",
        "# def format_time(time_str):\n",
        "#     if not time_str or len(time_str) != 4:\n",
        "#         return None\n",
        "#     hours = int(time_str[:2])\n",
        "#     minutes = time_str[2:]\n",
        "#     period = \"AM\" if hours < 12 else \"PM\"\n",
        "#     if hours > 12:\n",
        "#         hours -= 12\n",
        "#     elif hours == 0:\n",
        "#         hours = 12\n",
        "#     return f\"{hours}:{minutes} {period}\"\n",
        "\n",
        "# def course_to_structured_text(row):\n",
        "#     metadata_section = (\n",
        "#         \"=== COURSE METADATA ===\\n\"\n",
        "#         f\"Course Code: {row.get('Subject Course', '')}\\n\"\n",
        "#         f\"CRN: {str(row.get('CRN', ''))}\\n\"\n",
        "#         f\"Title: {row.get('Course Title', '')}\\n\"\n",
        "#     )\n",
        "\n",
        "#     campus = row.get('Campus Description', '')\n",
        "#     format_type = (\"Online\" if campus.lower() == 'online'\n",
        "#                   else \"Self-paced\" if campus.lower() == 'no campus, no room needed'\n",
        "#                   else \"In-Person\")\n",
        "#     location_section = (\n",
        "#         \"=== LOCATION ===\\n\"\n",
        "#         f\"Campus: {campus}\\n\"\n",
        "#         f\"Format: {format_type}\\n\"\n",
        "#     )\n",
        "\n",
        "#     begin_time = clean_time(row.get('Begin Time', ''))\n",
        "#     end_time = clean_time(row.get('End Time', ''))\n",
        "#     days = row.get('Days', '')\n",
        "#     schedule_section = \"=== SCHEDULE ===\\n\"\n",
        "#     if begin_time and end_time and days:\n",
        "#         schedule_section += (f\"Days: {days}\\n\"\n",
        "#                            f\"Time: {format_time(begin_time)} to {format_time(end_time)}\\n\")\n",
        "#     else:\n",
        "#         schedule_section += \"Schedule: Flexible/Self-paced\\n\"\n",
        "\n",
        "#     faculty = row.get('Faculty Name', '')\n",
        "#     instructor_section = (\n",
        "#         \"=== INSTRUCTOR ===\\n\"\n",
        "#         f\"Professor: {faculty if faculty else 'Not specified'}\\n\"\n",
        "#     )\n",
        "\n",
        "#     prerequisites = row.get('Prerequisites', '[]')\n",
        "#     prereq_text = (\"None required\" if prerequisites == '[]' or not prerequisites or prerequisites.strip() == ''\n",
        "#                   else prerequisites.strip('[]').replace(\"'\", \"\").replace('\"', ''))\n",
        "#     details_section = (\n",
        "#         \"=== COURSE DETAILS ===\\n\"\n",
        "#         f\"Term: {row.get('Term', '')}\\n\"\n",
        "#         f\"Prerequisites: {prereq_text}\\n\"\n",
        "#     )\n",
        "\n",
        "#     description = row.get('Course Description', '')\n",
        "#     description_section = (\n",
        "#         \"=== DESCRIPTION ===\\n\"\n",
        "#         f\"{description if description else 'No description available'}\\n\"\n",
        "#     )\n",
        "\n",
        "#     return (f\"{metadata_section.lower()}\\n\"\n",
        "#             f\"{location_section.lower()}\\n\"\n",
        "#             f\"{schedule_section.lower()}\\n\"\n",
        "#             f\"{instructor_section.lower()}\\n\"\n",
        "#             f\"{details_section.lower()}\\n\"\n",
        "#             f\"{description_section.lower()}\")\n",
        "\n",
        "# def process_course_data(file_path):\n",
        "#     df = pd.read_csv(file_path)\n",
        "#     return [course_to_structured_text(row) for _, row in df.iterrows()]\n",
        "\n",
        "# # Embedding Function\n",
        "# class CustomEmbeddingFunction:\n",
        "#     def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
        "#         self.model = SentenceTransformer(model_name)\n",
        "\n",
        "#     def __call__(self, input):\n",
        "#         if isinstance(input, str):\n",
        "#             input = [input]\n",
        "#         embeddings = self.model.encode(input, convert_to_numpy=True)\n",
        "#         if len(embeddings.shape) == 1:\n",
        "#             embeddings = np.expand_dims(embeddings, axis=0)\n",
        "#         return embeddings.tolist()\n",
        "\n",
        "\n",
        "\n",
        "# class CourseSearchSystem:\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         retriever_type: str = \"dense\",\n",
        "#         embedding_model_name: str = \"all-MiniLM-L6-v2\",\n",
        "#         device: str = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "#     ):\n",
        "#         self.device = device\n",
        "#         self.retriever_type = retriever_type\n",
        "#         self.documents = None\n",
        "\n",
        "#         if retriever_type == \"dense\":\n",
        "#             self.embedding_function = CustomEmbeddingFunction(embedding_model_name)\n",
        "#             self.chroma_client = chromadb.Client()\n",
        "#             try:\n",
        "#                 self.chroma_client.delete_collection(name=\"course_embeddings\")\n",
        "#             except:\n",
        "#                 pass\n",
        "#             self.collection = self.chroma_client.create_collection(\n",
        "#                 name=\"course_embeddings\",\n",
        "#                 embedding_function=self.embedding_function\n",
        "#             )\n",
        "#         elif retriever_type == \"bm25\":\n",
        "#             self.bm25 = None\n",
        "#             self.section_weights = {\n",
        "#                 \"metadata\": 2.0,  # Higher weight for course title/code matches\n",
        "#                 \"instructor\": 2.0,  # Higher weight for professor matches\n",
        "#                 \"details\": 1.5,  # Medium weight for term matches\n",
        "#                 \"location\": 1.5,  # Medium weight for campus matches\n",
        "#                 \"description\": 0.5  # Lower weight for general content\n",
        "#             }\n",
        "#         elif retriever_type == \"tfidf\":\n",
        "#             self.vectorizer = TfidfVectorizer(\n",
        "#                 lowercase=True,\n",
        "#                 token_pattern=r'(?u)\\b\\w+\\b|===\\s*\\w+\\s*===',  # Include section markers\n",
        "#                 ngram_range=(1, 2)  # Include bigrams for better matching\n",
        "#             )\n",
        "#             self.tfidf_matrix = None\n",
        "\n",
        "#     def preprocess_query(self, query):\n",
        "#         \"\"\"Extract structured information from query\"\"\"\n",
        "#         query_parts = {\n",
        "#             'course': None,\n",
        "#             'professor': None,\n",
        "#             'term': None,\n",
        "#             'campus': None\n",
        "#         }\n",
        "\n",
        "#         # Convert to lowercase for consistent matching\n",
        "#         query = query.lower()\n",
        "\n",
        "#         # Extract course information\n",
        "#         if 'algorithms' in query:\n",
        "#             query_parts['course'] = 'algorithms'\n",
        "#         elif 'artificial intelligence' in query:\n",
        "#             query_parts['course'] = 'artificial intelligence'\n",
        "\n",
        "#         # Extract professor name\n",
        "#         if 'rajagopal' in query or 'venkatesaramani' in query:\n",
        "#             query_parts['professor'] = 'venkatesaramani, rajagopal'\n",
        "\n",
        "#         # Extract term\n",
        "#         if 'spring 2025' in query:\n",
        "#             query_parts['term'] = 'spring 2025'\n",
        "\n",
        "#         # Extract campus\n",
        "#         if 'boston' in query:\n",
        "#             query_parts['campus'] = 'boston'\n",
        "\n",
        "#         return query_parts\n",
        "\n",
        "#     def enhance_query(self, query):\n",
        "#         \"\"\"Enhance query with structural information\"\"\"\n",
        "#         query_parts = self.preprocess_query(query)\n",
        "#         enhanced_query = query.lower()\n",
        "\n",
        "#         if query_parts['course']:\n",
        "#             enhanced_query += f\" === course metadata === title: {query_parts['course']}\"\n",
        "#         if query_parts['professor']:\n",
        "#             enhanced_query += f\" === instructor === professor: {query_parts['professor']}\"\n",
        "#         if query_parts['term']:\n",
        "#             enhanced_query += f\" === course details === term: {query_parts['term']}\"\n",
        "#         if query_parts['campus']:\n",
        "#             enhanced_query += f\" === location === campus: {query_parts['campus']}\"\n",
        "\n",
        "#         return enhanced_query, query_parts\n",
        "\n",
        "#     def add_course_sentences_to_db(self, course_data):\n",
        "#         self.documents = [doc for doc in course_data if doc is not None]\n",
        "\n",
        "#         if self.retriever_type == \"dense\":\n",
        "#             ids = [f\"course_{i}\" for i in range(len(self.documents))]\n",
        "#             self.collection.add(\n",
        "#                 documents=self.documents,\n",
        "#                 ids=ids\n",
        "#             )\n",
        "#         elif self.retriever_type == \"bm25\":\n",
        "#             # Create weighted document representations\n",
        "#             tokenized_docs = []\n",
        "#             for doc in self.documents:\n",
        "#                 tokens = []\n",
        "#                 for section in ['metadata', 'instructor', 'details', 'location']:\n",
        "#                     if f\"=== {section} ===\" in doc.lower():\n",
        "#                         # Add section markers with weights\n",
        "#                         weight = self.section_weights.get(section, 1.0)\n",
        "#                         section_tokens = doc.lower().split(f\"=== {section} ===\")[1].split(\"===\")[0].split()\n",
        "#                         tokens.extend(section_tokens * int(weight))\n",
        "#                 tokenized_docs.append(tokens)\n",
        "#             self.bm25 = BM25Okapi(tokenized_docs)\n",
        "\n",
        "#         elif self.retriever_type == \"tfidf\":\n",
        "#             # Include section markers in vectorization\n",
        "#             self.tfidf_matrix = self.vectorizer.fit_transform(self.documents)\n",
        "\n",
        "#     def query_courses(self, query_text, n_results=5):\n",
        "#         enhanced_query, query_parts = self.enhance_query(query_text)\n",
        "\n",
        "#         try:\n",
        "#             if self.retriever_type == \"dense\":\n",
        "#                 return self.collection.query(\n",
        "#                     query_texts=[enhanced_query],\n",
        "#                     n_results=n_results,\n",
        "#                     include=[\"documents\"]\n",
        "#                 )\n",
        "\n",
        "#             elif self.retriever_type == \"bm25\":\n",
        "#                 if not self.bm25:\n",
        "#                     return {\"documents\": [[\"No documents indexed\"]]}\n",
        "\n",
        "#                 # Create weighted query tokens\n",
        "#                 query_tokens = []\n",
        "#                 # Add query parts with appropriate weights\n",
        "#                 for part_type, part_value in query_parts.items():\n",
        "#                     if part_value:\n",
        "#                         weight = self.section_weights.get(part_type, 1.0)\n",
        "#                         tokens = part_value.split()\n",
        "#                         query_tokens.extend(tokens * int(weight))\n",
        "\n",
        "#                 # Add original query terms\n",
        "#                 query_tokens.extend(query_text.lower().split())\n",
        "\n",
        "#                 # Get scores and rank documents\n",
        "#                 scores = self.bm25.get_scores(query_tokens)\n",
        "#                 top_n = np.argsort(scores)[-n_results:][::-1]\n",
        "\n",
        "#                 # Filter results based on exact matches for critical fields\n",
        "#                 filtered_results = []\n",
        "#                 for idx in top_n:\n",
        "#                     doc = self.documents[idx]\n",
        "#                     doc_lower = doc.lower()\n",
        "\n",
        "#                     # Check for exact matches on critical fields\n",
        "#                     matches_all = True\n",
        "#                     if query_parts['course'] and query_parts['course'] not in doc_lower:\n",
        "#                         matches_all = False\n",
        "#                     if query_parts['professor'] and query_parts['professor'] not in doc_lower:\n",
        "#                         matches_all = False\n",
        "#                     if query_parts['term'] and query_parts['term'] not in doc_lower:\n",
        "#                         matches_all = False\n",
        "\n",
        "#                     if matches_all:\n",
        "#                         filtered_results.append(doc)\n",
        "\n",
        "#                 return {\"documents\": [filtered_results[:n_results]]}\n",
        "\n",
        "#             elif self.retriever_type == \"tfidf\":\n",
        "#                 if self.tfidf_matrix is None:\n",
        "#                     return {\"documents\": [[\"No documents indexed\"]]}\n",
        "\n",
        "#                 # Transform enhanced query\n",
        "#                 query_vec = self.vectorizer.transform([enhanced_query])\n",
        "#                 scores = (query_vec @ self.tfidf_matrix.T).toarray()[0]\n",
        "#                 top_n = np.argsort(scores)[-n_results:][::-1]\n",
        "\n",
        "#                 # Filter results similarly to BM25\n",
        "#                 filtered_results = []\n",
        "#                 for idx in top_n:\n",
        "#                     doc = self.documents[idx]\n",
        "#                     doc_lower = doc.lower()\n",
        "\n",
        "#                     matches_all = True\n",
        "#                     if query_parts['course'] and query_parts['course'] not in doc_lower:\n",
        "#                         matches_all = False\n",
        "#                     if query_parts['professor'] and query_parts['professor'] not in doc_lower:\n",
        "#                         matches_all = False\n",
        "#                     if query_parts['term'] and query_parts['term'] not in doc_lower:\n",
        "#                         matches_all = False\n",
        "\n",
        "#                     if matches_all:\n",
        "#                         filtered_results.append(doc)\n",
        "\n",
        "#                 return {\"documents\": [filtered_results[:n_results]]}\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error during {self.retriever_type} search: {e}\")\n",
        "#             return {\"documents\": [[\"Error occurred during search\"]]}\n",
        "\n",
        "# # Enhanced RAG Pipeline\n",
        "# class RAGPipeline:\n",
        "#     SYSTEM_INSTRUCTION = \"\"\"\n",
        "#         You are Curriculum compass, a chatbot which helps Northeastern University students find course offerings of their choice for the Spring 2025 semester.\n",
        "\n",
        "#         You have access to all the course offerings for the Spring 2025 semester, your objective is to use this context to answer student questions.\n",
        "\n",
        "#         Instructions:\n",
        "#         1. Students may not mention the names of the courses properly. Their input could have typo's, mistakes. For example, students could input 'PDP' instead of\n",
        "#         'Programming Design Paradigm' or they could mention 'Raj Venkat' instead of the full name of the professor 'Rajagopal Venkatesaramani'\n",
        "#         \"\"\"\n",
        "\n",
        "#     def __init__(self, course_search_system):\n",
        "#         self.course_search_system = course_search_system\n",
        "#         model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "#         self.model = AutoModelForCausalLM.from_pretrained(\n",
        "#             model_name,\n",
        "#             torch_dtype=\"auto\",\n",
        "#             device_map=\"auto\"\n",
        "#         )\n",
        "#         self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#     def generate_response(self, query, retrieved_docs):\n",
        "#         context = \"\\n\\n\".join([doc for sublist in retrieved_docs for doc in sublist])\n",
        "#         prompt = f\"\"\"Context:{context}, Query: {query}\"\"\"\n",
        "\n",
        "#         messages = [\n",
        "#             {\"role\": \"system\", \"content\": self.SYSTEM_INSTRUCTION},\n",
        "#             {\"role\": \"user\", \"content\": prompt}\n",
        "#         ]\n",
        "\n",
        "#         text = self.tokenizer.apply_chat_template(\n",
        "#             messages,\n",
        "#             tokenize=False,\n",
        "#             add_generation_prompt=True\n",
        "#         )\n",
        "\n",
        "#         model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "#         generated_ids = self.model.generate(\n",
        "#             **model_inputs,\n",
        "#             max_new_tokens=4500,\n",
        "#             temperature=0.1\n",
        "#         )\n",
        "\n",
        "#         generated_ids = [\n",
        "#             output_ids[len(input_ids):]\n",
        "#             for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "#         ]\n",
        "\n",
        "#         return self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "#     def __call__(self, query, top_k=10):\n",
        "#         print(f\"Processing query: {query}\")\n",
        "#         print(\"Retrieving relevant course information...\")\n",
        "#         results = self.course_search_system.query_courses(query, top_k)\n",
        "\n",
        "#         print(\"Results:\")\n",
        "#         print(results[\"documents\"])\n",
        "\n",
        "#         print(\"Generating response...\")\n",
        "#         response = self.generate_response(query, results[\"documents\"])\n",
        "#         return response\n",
        "\n",
        "# def main():\n",
        "#     # Load course data\n",
        "#     course_sentences = process_course_data('/content/drive/MyDrive/course_registration/courses.csv')\n",
        "\n",
        "#     # Initialize retrievers\n",
        "#     retrievers = {\n",
        "#         \"dense\": CourseSearchSystem(retriever_type=\"dense\"),\n",
        "#         \"bm25\": CourseSearchSystem(retriever_type=\"bm25\"),\n",
        "#         \"tfidf\": CourseSearchSystem(retriever_type=\"tfidf\")\n",
        "#     }\n",
        "\n",
        "#     # Initialize and index documents for each retriever\n",
        "#     for system in retrievers.values():\n",
        "#         system.add_course_sentences_to_db(course_sentences)\n",
        "\n",
        "#     # Create RAG pipelines\n",
        "#     rag_pipelines = {name: RAGPipeline(system) for name, system in retrievers.items()}\n",
        "\n",
        "#     # Test queries\n",
        "#     example_queries = [\n",
        "#         \"Are there any prerequisite courses for Artificial Intelligence for Human Computer Interaction?\"\n",
        "#     ]\n",
        "\n",
        "#     # Process queries with each retriever\n",
        "#     for query in example_queries:\n",
        "#         print(\"\\n\" + \"=\"*50)\n",
        "#         print(f\"Query: {query}\")\n",
        "\n",
        "#         for name, pipeline in rag_pipelines.items():\n",
        "#             print(f\"\\n{name.upper()} Retriever Results:\")\n",
        "#             print(\"-\" * 30)\n",
        "#             try:\n",
        "#                 response = pipeline(query)\n",
        "#                 print(response)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error with {name} retriever: {e}\")\n",
        "#             print(\"-\" * 30)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
